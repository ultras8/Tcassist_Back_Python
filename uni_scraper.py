import asyncio
import re
import os
from playwright.async_api import async_playwright

async def mega_university_scanner_v3_fixed():
    target_unis = [
        "001", "002", "003", "004", "005", "006", "007", "008", "009", "010",
        "011", "012", "013", "014", "015", "016", "017", "018", "019", "020"
    ]
    
    filename = "mega_unis_links.txt"
    
    # --- 1. ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡∏∂‡πâ‡∏ô‡∏°‡∏≤‡∏à‡∏≥‡πÑ‡∏ß‡πâ‡∏Å‡πà‡∏≠‡∏ô ---
    existing_links = set()
    if os.path.exists(filename):
        with open(filename, "r", encoding="utf-8") as f:
            existing_links = set(line.strip() for line in f if line.strip())
    
    print(f"üìÇ ‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏î‡∏¥‡∏°‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå: {len(existing_links)} ‡∏•‡∏¥‡πâ‡∏á‡∏Å‡πå")
    print(f"üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏†‡∏≤‡∏£‡∏Å‡∏¥‡∏à Mega Scanner: ‡∏Å‡∏ß‡∏≤‡∏î‡∏•‡πâ‡∏≤‡∏á 20 ‡∏™‡∏ñ‡∏≤‡∏ö‡∏±‡∏ô")

    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=False)
        page = await browser.new_page()

        for uni_id in target_unis:
            all_program_urls = set() # ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡∏≠‡∏á‡∏£‡∏≠‡∏ö‡∏ô‡∏µ‡πâ
            try:
                print(f"üè¢ ‡∏ö‡∏∏‡∏Å‡∏°‡∏´‡∏≤‡∏•‡∏±‡∏¢: {uni_id}")
                await page.goto(f"https://course.mytcas.com/universities/{uni_id}", wait_until="domcontentloaded")
                await asyncio.sleep(2)

                # 1. ‡∏•‡πà‡∏≤‡∏•‡∏¥‡πâ‡∏á‡∏Å‡πå‡∏Ñ‡∏ì‡∏∞
                faculty_links = [f"https://course.mytcas.com{await a.get_attribute('href')}" 
                                 for a in await page.query_selector_all('a[href*="/faculties/"]')]

                for f_url in faculty_links:
                    print(f"   üîé ‡∏™‡πÅ‡∏Å‡∏ô‡∏Ñ‡∏ì‡∏∞: {f_url.split('/')[-1]}")
                    await page.goto(f_url, wait_until="domcontentloaded")
                    
                    field_links = [f"https://course.mytcas.com{await a.get_attribute('href')}" 
                                   for a in await page.query_selector_all('a[href*="/fields/"]')]
                    
                    targets_to_scan = field_links if field_links else [f_url]

                    for target_url in targets_to_scan:
                        try:
                            if target_url != f_url:
                                await page.goto(target_url, wait_until="domcontentloaded")
                            
                            await asyncio.sleep(1)
                            content = await page.content()
                            found_codes = re.findall(r'/programs/([0-9A-Z]{15})', content)
                            
                            if not found_codes:
                                found_codes = re.findall(r'\b\d{14}[0-9A-Z]\b', content)

                            for code in found_codes:
                                full_url = f"https://course.mytcas.com/programs/{code}"
                                # ‚ú® ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏•‡∏¥‡πâ‡∏á‡∏Å‡πå‡∏ô‡∏µ‡πâ‡πÑ‡∏°‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô "‡∏Ç‡∏≠‡∏á‡πÄ‡∏Å‡πà‡∏≤" ‡πÅ‡∏•‡∏∞ "‡∏Ç‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏á‡πÄ‡∏à‡∏≠"
                                if full_url not in existing_links and full_url not in all_program_urls:
                                    all_program_urls.add(full_url)
                        except:
                            continue
                
                # --- 2. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡πÄ‡∏â‡∏û‡∏≤‡∏∞ "‡∏Ç‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà" ‡∏ï‡πà‡∏≠‡∏ó‡πâ‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå (Append) ---
                if all_program_urls:
                    new_links_list = sorted(list(all_program_urls))
                    with open(filename, "a", encoding="utf-8") as f:
                        for link in new_links_list:
                            f.write(f"{link}\n")
                    
                    # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï existing_links ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏±‡∏ô‡∏ã‡πâ‡∏≥‡πÉ‡∏ô‡∏°‡∏´‡∏≤‡∏•‡∏±‡∏¢‡∏ñ‡∏±‡∏î‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢
                    existing_links.update(all_program_urls)
                    print(f"‚úÖ ‡∏à‡∏ö‡∏°‡∏´‡∏≤‡∏•‡∏±‡∏¢ {uni_id} ‡πÄ‡∏ã‡∏ü‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÉ‡∏´‡∏°‡πà: {len(all_program_urls)} ‡∏•‡∏¥‡πâ‡∏á‡∏Å‡πå")
                else:
                    print(f"‚úÖ ‡∏à‡∏ö‡∏°‡∏´‡∏≤‡∏•‡∏±‡∏¢ {uni_id} (‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏•‡∏¥‡πâ‡∏á‡∏Å‡πå‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå)")

            except Exception as e:
                print(f"‚ö†Ô∏è ‡∏°‡∏´‡∏≤‡∏•‡∏±‡∏¢ {uni_id} ‡∏Ç‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏á: {e}")

        await browser.close()
        print(f"üèÜ ‡∏†‡∏≤‡∏£‡∏Å‡∏¥‡∏à‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! ‡∏¢‡∏≠‡∏î‡∏£‡∏ß‡∏°‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠: {len(existing_links)} ‡∏•‡∏¥‡πâ‡∏á‡∏Å‡πå!")

if __name__ == "__main__":
    asyncio.run(mega_university_scanner_v3_fixed())